
@article{ray_signal_2018,
	title = {Signal Adaptive Variable Selector for the Horseshoe Prior},
	abstract = {In this article, we propose a simple method to perform variable selection as a post model-fitting exercise using continuous shrinkage priors such as the popular horseshoe prior. The proposed Signal Adaptive Variable Selector ({SAVS}) approach post-processes a point estimate such as the posterior mean to group the variables into signals and nulls. The approach is completely automated and does not require specification of any tuning parameters. We carried out a comprehensive simulation study to compare the performance of the proposed {SAVS} approach to frequentist penalization procedures and Bayesian model selection procedures. {SAVS} was found to be highly competitive across all the settings considered, and was particularly found to be robust to correlated designs. We also applied {SAVS} to a genomic dataset with more than 20,000 covariates to illustrate its scalability.},
	author = {Ray, Pallavi and Bhattacharya, Anirban},
	date = {2018-10},
	file = {Ray and Bhattacharya - 2018 - Signal Adaptive Variable Selector for the Horsesho.pdf:/Users/phipag/Zotero/storage/GX3KKMBG/Ray and Bhattacharya - 2018 - Signal Adaptive Variable Selector for the Horsesho.pdf:application/pdf}
}

@article{hahn_decoupling_2015,
	title = {Decoupling Shrinkage and Selection in Bayesian Linear Models: A Posterior Summary Perspective},
	volume = {110},
	url = {https://doi.org/10.1080/01621459.2014.993077},
	doi = {10.1080/01621459.2014.993077},
	pages = {435--448},
	number = {509},
	journaltitle = {Journal of the American Statistical Association},
	author = {Hahn, P. Richard and Carvalho, Carlos M.},
	date = {2015},
	note = {Publisher: Taylor \& Francis},
	file = {Hahn and Carvalho - 2015 - Decoupling Shrinkage and Selection in Bayesian Lin.pdf:/Users/phipag/Zotero/storage/58H3WHKD/Hahn and Carvalho - 2015 - Decoupling Shrinkage and Selection in Bayesian Lin.pdf:application/pdf}
}

@article{huber_inducing_2021,
	title = {Inducing Sparsity and Shrinkage in Time-Varying Parameter Models},
	volume = {39},
	url = {https://doi.org/10.1080/07350015.2020.1713796},
	doi = {10.1080/07350015.2020.1713796},
	pages = {669--683},
	number = {3},
	journaltitle = {Journal of Business \& Economic Statistics},
	author = {Huber, Florian and Koop, Gary and Onorante, Luca},
	date = {2021},
	note = {Publisher: Taylor \& Francis},
	file = {Huber et al. - 2021 - Inducing Sparsity and Shrinkage in Time-Varying Pa.pdf:/Users/phipag/Zotero/storage/NCP98FE8/Huber et al. - 2021 - Inducing Sparsity and Shrinkage in Time-Varying Pa.pdf:application/pdf}
}

@article{kadiyala_numerical_1997,
	title = {Numerical methods for estimation and inference in Bayesian {VAR}-models},
	volume = {12},
	pages = {99--132},
	number = {2},
	journaltitle = {Journal of Applied Econometrics},
	author = {Kadiyala, K. Rao and Karlsson, Sune},
	date = {1997},
	note = {Publisher: Wiley Online Library},
	file = {Kadiyala and Karlsson - 1997 - Numerical methods for estimation and inference in .pdf:/Users/phipag/Zotero/storage/L6QXJAMW/Kadiyala and Karlsson - 1997 - Numerical methods for estimation and inference in .pdf:application/pdf}
}

@article{koop_forecasting_2013,
	title = {Forecasting with Medium and Large Bayesian {VARS}},
	volume = {28},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jae.1270},
	doi = {https://doi.org/10.1002/jae.1270},
	abstract = {{SUMMARY} This paper is motivated by the recent interest in the use of Bayesian {VARs} for forecasting, even in cases where the number of dependent variables is large. In such cases factor methods have been traditionally used, but recent work using a particular prior suggests that Bayesian {VAR} methods can forecast better. In this paper, we consider a range of alternative priors which have been used with small {VARs}, discuss the issues which arise when they are used with medium and large {VARs} and examine their forecast performance using a {US} macroeconomic dataset containing 168 variables. We find that Bayesian {VARs} do tend to forecast better than factor methods and provide an extensive comparison of the strengths and weaknesses of various approaches. Typically, we find that the simple Minnesota prior forecasts well in medium and large {VARs}, which makes this prior attractive relative to computationally more demanding alternatives. Our empirical results show the importance of using forecast metrics based on the entire predictive density, instead of relying solely on those based on point forecasts. Copyright © 2011 John Wiley \& Sons, Ltd.},
	pages = {177--203},
	number = {2},
	journaltitle = {Journal of Applied Econometrics},
	author = {Koop, Gary M.},
	date = {2013},
	file = {Koop - 2013 - Forecasting with Medium and Large Bayesian VARS.pdf:/Users/phipag/Zotero/storage/65TZUACK/Koop - 2013 - Forecasting with Medium and Large Bayesian VARS.pdf:application/pdf}
}

@article{hinkley_predictive_1979,
	title = {Predictive Likelihood},
	volume = {7},
	url = {https://doi.org/10.1214/aos/1176344723},
	doi = {10.1214/aos/1176344723},
	pages = {718 -- 728},
	number = {4},
	journaltitle = {The Annals of Statistics},
	author = {Hinkley, David},
	date = {1979},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Bayesian methods, Confidence regions, exponential families, likelihood, prediction, statistical inference},
	file = {Hinkley - 1979 - Predictive Likelihood.pdf:/Users/phipag/Zotero/storage/AHDPGES9/Hinkley - 1979 - Predictive Likelihood.pdf:application/pdf}
}

@article{george_bayesian_2008,
	title = {Bayesian stochastic search for {VAR} model restrictions},
	volume = {142},
	issn = {0304-4076},
	url = {https://www.sciencedirect.com/science/article/pii/S0304407607001753},
	doi = {https://doi.org/10.1016/j.jeconom.2007.08.017},
	abstract = {We propose a Bayesian stochastic search approach to selecting restrictions for vector autoregressive ({VAR}) models. For this purpose, we develop a Markov chain Monte Carlo ({MCMC}) algorithm that visits high posterior probability restrictions on the elements of both the {VAR} regression coefficients and the error variance matrix. Numerical simulations show that stochastic search based on this algorithm can be effective at both selecting a satisfactory model and improving forecasting performance. To illustrate the potential of our approach, we apply our stochastic search to {VAR} modeling of inflation transmission from producer price index ({PPI}) components to the consumer price index ({CPI}).},
	pages = {553--580},
	number = {1},
	journaltitle = {Journal of Econometrics},
	author = {George, Edward I. and Sun, Dongchu and Ni, Shawn},
	date = {2008},
	keywords = {Bayesian {VAR}, Markov chain Monte Carlo, Stochastic search},
	file = {George et al. - 2008 - Bayesian stochastic search for VAR model restricti.pdf:/Users/phipag/Zotero/storage/4HRZADHD/George et al. - 2008 - Bayesian stochastic search for VAR model restricti.pdf:application/pdf}
}

@article{koop_bayesian_2009,
	title = {Bayesian Multivariate Time Series Methods for Empirical Macroeconomics},
	volume = {3},
	issn = {1551-3076, 1551-3084},
	url = {http://www.nowpublishers.com/article/Details/ECO-013},
	doi = {10.1561/0800000013},
	pages = {267--358},
	number = {4},
	journaltitle = {Foundations and Trends® in Econometrics},
	shortjournal = {{FNT} in Econometrics},
	author = {Koop, Gary and {Korobilis, Dimitris}},
	urldate = {2022-01-06},
	date = {2009},
	langid = {english},
	file = {koop_korobilis_Foundations_and_Trends_2010.pdf:/Users/phipag/Zotero/storage/L5XP4PA4/koop_korobilis_Foundations_and_Trends_2010.pdf:application/pdf}
}

@book{gelman_bayesian_2013,
	edition = {3},
	title = {Bayesian Data Analysis},
	isbn = {978-0-429-11307-9},
	url = {https://www.taylorfrancis.com/books/9781439898208},
	publisher = {Chapman and Hall/{CRC}},
	author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
	urldate = {2022-01-09},
	date = {2013-11-27},
	langid = {english},
	doi = {10.1201/b16018},
	file = {Gelman et al. - Bayesian Data Analysis Third edition (with errors .pdf:/Users/phipag/Zotero/storage/EDSJJGMQ/Gelman et al. - Bayesian Data Analysis Third edition (with errors .pdf:application/pdf}
}

@article{ando_predictive_2010,
	title = {Predictive likelihood for Bayesian model selection and averaging},
	volume = {26},
	issn = {0169-2070},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207009001290},
	doi = {https://doi.org/10.1016/j.ijforecast.2009.08.001},
	abstract = {This paper investigates the performance of the predictive distributions of Bayesian models. To overcome the difficulty of evaluating the predictive likelihood, we introduce the concept of expected log-predictive likelihoods for Bayesian models, and propose an estimator of the expected log-predictive likelihood. The estimator is derived by correcting the asymptotic bias of the log-likelihood of the predictive distribution as an estimate of its expected value. We investigate the relationship between the proposed criterion and the traditional information criteria and show that the proposed criterion is a natural extension of the traditional ones. A new model selection criterion and a new model averaging method are then developed, with the weights for the individual models being dependent on their expected log-predictive likelihoods. We examine the performance of the proposed method using Monte Carlo experiments and a real example, which concerns the prediction of quarterly growth rates of real gross domestic product in the G7 countries. Out-of-sample forecasts show that the proposed methodology outperforms other methods available in the literature.},
	pages = {744--763},
	number = {4},
	journaltitle = {International Journal of Forecasting},
	author = {Ando, Tomohiro and Tsay, Ruey},
	date = {2010},
	keywords = {Finance, Model averaging, Model selection, Predictive likelihood},
	file = {Ando and Tsay - 2010 - Predictive likelihood for Bayesian model selection.pdf:/Users/phipag/Zotero/storage/CV9ZGSVY/Ando and Tsay - 2010 - Predictive likelihood for Bayesian model selection.pdf:application/pdf}
}

@article{vehtari_practical_2017,
	title = {Practical Bayesian model evaluation using leave-one-out cross-validation and {WAIC}},
	volume = {27},
	issn = {0960-3174, 1573-1375},
	url = {http://link.springer.com/10.1007/s11222-016-9696-4},
	doi = {10.1007/s11222-016-9696-4},
	pages = {1413--1432},
	number = {5},
	journaltitle = {Statistics and Computing},
	shortjournal = {Stat Comput},
	author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
	urldate = {2022-01-11},
	date = {2017-09},
	langid = {english},
	file = {Submitted Version:/Users/phipag/Zotero/storage/DANZ3G9U/Vehtari et al. - 2017 - Practical Bayesian model evaluation using leave-on.pdf:application/pdf;Vehtari2017_Article_PracticalBayesianModelEvaluati.pdf:/Users/phipag/Zotero/storage/MNW4FDUS/Vehtari2017_Article_PracticalBayesianModelEvaluati.pdf:application/pdf}
}

@article{tibshirani_regression_1996,
	title = {Regression Shrinkage and Selection via the Lasso},
	volume = {58},
	issn = {00359246},
	url = {http://www.jstor.org/stable/2346178},
	abstract = {We propose a new method for estimation in linear models. The `lasso' minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.},
	pages = {267--288},
	number = {1},
	journaltitle = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Tibshirani, Robert},
	date = {1996},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	file = {Tibshirani - 1996 - Regression Shrinkage and Selection via the Lasso.pdf:/Users/phipag/Zotero/storage/9KI28ZZN/Tibshirani - 1996 - Regression Shrinkage and Selection via the Lasso.pdf:application/pdf}
}

@article{park_bayesian_2008,
	title = {The Bayesian Lasso},
	volume = {103},
	pages = {681 -- 686},
	journaltitle = {Journal of the American Statistical Association},
	author = {Park, Trevor H. and Casella, George},
	date = {2008},
	file = {Park and Casella - 2008 - The Bayesian Lasso.pdf:/Users/phipag/Zotero/storage/U3Y8P3TZ/Park and Casella - 2008 - The Bayesian Lasso.pdf:application/pdf}
}

@article{hoerl_ridge_2000,
	title = {Ridge Regression: Biased Estimation for Nonorthogonal Problems},
	volume = {42},
	issn = {0040-1706, 1537-2723},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00401706.2000.10485983},
	doi = {10.1080/00401706.2000.10485983},
	shorttitle = {Ridge Regression},
	pages = {80--86},
	number = {1},
	journaltitle = {Technometrics},
	shortjournal = {Technometrics},
	author = {Hoerl, Arthur E. and Kennard, Robert W.},
	urldate = {2022-01-13},
	date = {2000-02},
	langid = {english},
	file = {Hoerl and Kennard - 2000 - Ridge Regression Biased Estimation for Nonorthogo.pdf:/Users/phipag/Zotero/storage/RYYV8ECV/Hoerl and Kennard - 2000 - Ridge Regression Biased Estimation for Nonorthogo.pdf:application/pdf}
}

@article{hauzenberger_combining_2020,
	title = {Combining Shrinkage and Sparsity in Conjugate Vector Autoregressive Models},
	url = {http://arxiv.org/abs/2002.08760},
	abstract = {Conjugate priors allow for fast inference in large dimensional vector autoregressive ({VAR}) models but, at the same time, introduce the restriction that each equation features the same set of explanatory variables. This paper proposes a straightforward means of post-processing posterior estimates of a conjugate Bayesian {VAR} to effectively perform equation-specific covariate selection. Compared to existing techniques using shrinkage alone, our approach combines shrinkage and sparsity in both the {VAR} coefficients and the error variance-covariance matrices, greatly reducing estimation uncertainty in large dimensions while maintaining computational tractability. We illustrate our approach by means of two applications. The first application uses synthetic data to investigate the properties of the model across different data-generating processes, the second application analyzes the predictive gains from sparsification in a forecasting exercise for {US} data.},
	journaltitle = {{arXiv}:2002.08760 [econ]},
	author = {Hauzenberger, Niko and Huber, Florian and Onorante, Luca},
	urldate = {2022-01-15},
	date = {2020-08-26},
	eprinttype = {arxiv},
	eprint = {2002.08760},
	keywords = {Economics - Econometrics},
	file = {arXiv Fulltext PDF:/Users/phipag/Zotero/storage/DXXSMM5E/Hauzenberger et al. - 2020 - Combining Shrinkage and Sparsity in Conjugate Vect.pdf:application/pdf;arXiv.org Snapshot:/Users/phipag/Zotero/storage/KZXJ3842/2002.html:text/html}
}

@article{banbura_large_2010,
	title = {Large Bayesian vector auto regressions},
	volume = {25},
	issn = {0883-7252, 1099-1255},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/jae.1137},
	doi = {10.1002/jae.1137},
	pages = {71--92},
	number = {1},
	journaltitle = {Journal of Applied Econometrics},
	shortjournal = {J. Appl. Econ.},
	author = {Bańbura, Marta and Giannone, Domenico and Reichlin, Lucrezia},
	urldate = {2022-01-17},
	date = {2010-01},
	langid = {english},
	file = {Bańbura et al. - 2010 - Large Bayesian vector auto regressions.pdf:/Users/phipag/Zotero/storage/9L9IJU6H/Bańbura et al. - 2010 - Large Bayesian vector auto regressions.pdf:application/pdf}
}

@report{mccracken_fred-md_2015,
	title = {{FRED}-{MD}: A Monthly Database for Macroeconomic Research},
	url = {https://research.stlouisfed.org/wp/more/2015-012},
	shorttitle = {{FRED}-{MD}},
	author = {{McCracken}, Michael W. and Ng, Serena},
	urldate = {2022-01-17},
	date = {2015},
	langid = {english},
	doi = {10.20955/wp.2015.012},
	file = {2015-012.pdf:/Users/phipag/Zotero/storage/CZD2BQYB/2015-012.pdf:application/pdf;Full Text:/Users/phipag/Zotero/storage/QYMFCPDF/McCracken and Ng - 2015 - FRED-MD A Monthly Database for Macroeconomic Rese.pdf:application/pdf}
}

@article{giannone_prior_2015,
	title = {Prior Selection for Vector Autoregressions},
	volume = {97},
	issn = {0034-6535, 1530-9142},
	url = {https://direct.mit.edu/rest/article/97/2/436-451/58236},
	doi = {10.1162/REST_a_00483},
	pages = {436--451},
	number = {2},
	journaltitle = {Review of Economics and Statistics},
	shortjournal = {Review of Economics and Statistics},
	author = {Giannone, Domenico and Lenza, Michele and Primiceri, Giorgio E.},
	urldate = {2022-01-18},
	date = {2015-05},
	langid = {english},
	file = {Full Text:/Users/phipag/Zotero/storage/LBISN3IB/Giannone et al. - 2015 - Prior Selection for Vector Autoregressions.pdf:application/pdf}
}